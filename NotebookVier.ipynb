{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model that uses the fenchel-young loss and trains on 200 images \n",
    "# the images are permuted in 9 tiles and in every iteration a new permutation is generated.\n",
    "# we use a deep encoder with fixed parameters, adam optimizer, preprocessing before tiling  \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple___Apple_scab Apple___Black_rot Apple___Cedar_apple_rust Apple___healthy 1644\n"
     ]
    }
   ],
   "source": [
    "from ast import Pass\n",
    "import platform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "number_of_images = -1\n",
    "\n",
    "root = os.getcwd() # Don't change this\n",
    "data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "p = Path(root + data_dirname)\n",
    "p.mkdir(exist_ok=True) \n",
    "if platform.system()=='Darwin':\n",
    "  root = os.getcwd() # Don't change this\n",
    "  data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "  p = Path(root + data_dirname)\n",
    "  p.mkdir(exist_ok=True) \n",
    "else:\n",
    "  #p = Path(\"C:/Users/mwels/Documents/Uni/11. Semester/Deep learning in visual recognition/Plant_leave_diseases_dataset_without_augmentation\")\n",
    "  #p.mkdir(exist_ok=True)\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "classes = [\n",
    "  'Apple___Apple_scab',\n",
    "  'Apple___healthy',\n",
    "  'Apple___Black_rot',\n",
    "  'Apple___Cedar_apple_rust',\n",
    "  \"all\"\n",
    "  ]\n",
    "\n",
    "if \"all\" in classes:\n",
    "  classes = os.listdir(p)\n",
    "\n",
    "for c in classes:\n",
    "  print(c,end=\" \")\n",
    "  filelist = [x for x in (p/c).iterdir() if x.is_file()]\n",
    "  for f in filelist:\n",
    "    img = cv2.imread(str(f))\n",
    "    if img is None:\n",
    "      print(f'Failed to open {f}. Deleting file')\n",
    "      os.remove(str(f))\n",
    "\n",
    "\n",
    "filelist = filelist[:number_of_images]\n",
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilex = 3\n",
    "number_of_tiles = tilex**2\n",
    "number_of_permutations = 1000\n",
    "target_siz = (224,224,3)\n",
    "tile_size = target_siz[0]//tilex\n",
    "sfmax = True\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "conv_base = MobileNet(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=target_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Flatten, Lambda, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import os\n",
    "\n",
    "\n",
    "#tiles = Input((number_of_tiles,tile_size,tile_size,3))\n",
    "tiles = Input(target_siz)\n",
    "\n",
    "inputs = {}\n",
    "layers = {}\n",
    "embedds = {}\n",
    "\n",
    "shared_conv = conv_base \n",
    "\n",
    "# for i in range(number_of_tiles):\n",
    "#     #inputs[f'tiles{i}'] = Input((tile_size,tile_size,3))\n",
    "#     #layers[f'tile{i}'] = Lambda(lambda x: x[:,i,:,:,:])(tiles)\n",
    "\n",
    "#     #layers[f'deep_layers{i}'] = shared_conv(inputs[f'tiles{i}'])\n",
    "#     layers[f'deep_layers{i}'] = shared_conv(layers[f'tile{i}'])\n",
    "#     embedds[f'embedd{i}'] = Flatten()(layers[f'deep_layers{i}'])\n",
    "#concatonation = Concatenate(axis=1)(list(embedds.values()))\n",
    "\n",
    "concatonation = shared_conv(tiles)\n",
    "concatonation = GlobalAveragePooling2D()(concatonation)\n",
    "\n",
    "out = Dense(number_of_tiles*10, activation=\"relu\", kernel_initializer='he_normal')(concatonation)\n",
    "if sfmax:\n",
    "    out = Dense(number_of_permutations, activation=\"softmax\", kernel_initializer='he_normal')(out)\n",
    "else:\n",
    "    out = Dense(number_of_tiles, kernel_initializer='he_normal')(out)\n",
    "out = Flatten()(out)\n",
    "\n",
    "model = Model(inputs=tiles, outputs=out)\n",
    "#model = Model(inputs=list(inputs.values()), outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \n",
    "    show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_1   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 90)                92250     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1000)              91000     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,412,114\n",
      "Trainable params: 3,390,226\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers is 6\n",
      "Number of pretrained base layers is 86\n"
     ]
    }
   ],
   "source": [
    "total_num_layers = len(model.layers)\n",
    "num_base_layers = len(conv_base.layers)\n",
    "print(f\"Total number of layers is {total_num_layers}\")\n",
    "print(f\"Number of pretrained base layers is {num_base_layers}\")\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[3:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.PermOneHotDataGen import *\n",
    "from src.model_tools import *\n",
    "from src.permutation_tools import *\n",
    "\n",
    "x_train, x_test = train_test_split(filelist)\n",
    "\n",
    "train_generator = PermOneHotDataGen(x_train,\n",
    "                                    batch_size=8,\n",
    "                                    tilenumberx=tilex, \n",
    "                                    shuffle_permutations=True)\n",
    "\n",
    "validation_generator = PermOneHotDataGen(x_test,\n",
    "                                        batch_size=8,\n",
    "                                        tilenumberx=tilex,\n",
    "                                        shuffle_permutations=True)\n",
    "\n",
    "train_generator_sm = PermOneHotDataGen(x_train,\n",
    "                                    batch_size=1,\n",
    "                                    tilenumberx=tilex, max_perms=number_of_permutations)\n",
    "\n",
    "validation_generator_sm = PermOneHotDataGen(x_test,\n",
    "                                        batch_size=1,\n",
    "                                        tilenumberx=tilex, max_perms=number_of_permutations)\n",
    "\n",
    "train_stitch_sm = PermOneHotDataGen(x_train,\n",
    "                                    batch_size=16,\n",
    "                                    tilenumberx=tilex,\n",
    "                                    shuffle_permutations=True,\n",
    "                                    max_perms=number_of_permutations,\n",
    "                                    target_size=target_siz, \n",
    "                                    stitched=True,\n",
    "                                    one_hot_encoding=True)\n",
    "\n",
    "validation_stitch_sm = PermOneHotDataGen(x_test,\n",
    "                                        batch_size=len(x_test),\n",
    "                                        tilenumberx=tilex, \n",
    "                                        max_perms=number_of_permutations, \n",
    "                                        target_size=target_siz, \n",
    "                                        stitched=True,\n",
    "                                        one_hot_encoding=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "if sfmax:\n",
    "    model.compile(optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=RankingLoss(),\n",
    "        metrics=[ProjectedRanksAccuracy(), PartialRanksAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 9)\n",
      "(1, 9)\n",
      "(8, 9)\n",
      "(1, 9)\n",
      "(8, 9, 85, 85, 3)\n",
      "(1, 9, 85, 85, 3)\n",
      "(8, 9, 85, 85, 3)\n",
      "(1, 9, 85, 85, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.next()[1].shape)\n",
    "print(train_generator_sm.next()[1].shape)\n",
    "print(validation_generator.next()[1].shape)\n",
    "print(validation_generator_sm.next()[1].shape)\n",
    "print(train_generator.next()[0].shape)\n",
    "print(train_generator_sm.next()[0].shape)\n",
    "print(validation_generator.next()[0].shape)\n",
    "print(validation_generator_sm.next()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProjectedRanksAccuracy().update_state(validation_generator.next()[1], validation_generator.next()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "78/78 [==============================] - 19s 231ms/step - loss: 6.9745 - accuracy: 0.0016 - val_loss: 6.9092 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "78/78 [==============================] - 17s 220ms/step - loss: 6.8361 - accuracy: 0.0041 - val_loss: 6.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "78/78 [==============================] - 17s 213ms/step - loss: 6.6325 - accuracy: 0.0081 - val_loss: 7.0591 - val_accuracy: 0.0024\n",
      "Epoch 4/10\n",
      "78/78 [==============================] - 17s 212ms/step - loss: 6.3104 - accuracy: 0.0154 - val_loss: 7.2956 - val_accuracy: 0.0024\n",
      "Epoch 5/10\n",
      "78/78 [==============================] - 17s 212ms/step - loss: 5.9992 - accuracy: 0.0203 - val_loss: 7.6331 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "78/78 [==============================] - 17s 212ms/step - loss: 5.6799 - accuracy: 0.0333 - val_loss: 8.0010 - val_accuracy: 0.0024\n",
      "Epoch 7/10\n",
      "78/78 [==============================] - 17s 213ms/step - loss: 5.3856 - accuracy: 0.0543 - val_loss: 8.3025 - val_accuracy: 0.0024\n",
      "Epoch 8/10\n",
      "78/78 [==============================] - 17s 213ms/step - loss: 5.0895 - accuracy: 0.0714 - val_loss: 8.6690 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "52/78 [===================>..........] - ETA: 4s - loss: 4.7467 - accuracy: 0.1065"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m nb_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_stitch_sm,\n\u001b[0;32m      4\u001b[0m           epochs \u001b[39m=\u001b[39;49m nb_epochs,\n\u001b[0;32m      5\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_stitch_sm,\n\u001b[0;32m      6\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs = 10\n",
    "\n",
    "model.fit(train_stitch_sm,\n",
    "          epochs = nb_epochs,\n",
    "          validation_data=validation_stitch_sm,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#model.save(\"models/2022_10_27__01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b8d5e587a4510d8571f088dd45f32758fc85cc5ecc1468b35b5979219c430b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
