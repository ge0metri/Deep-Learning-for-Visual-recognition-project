{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model that uses the fenchel-young loss and trains on 200 images \n",
    "# the images are permuted in 9 tiles and in every iteration a new permutation is generated.\n",
    "# we use a deep encoder with fixed parameters, adam optimizer, preprocessing before tiling  \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple___Apple_scab Apple___Black_rot Apple___Cedar_apple_rust Apple___healthy 250\n"
     ]
    }
   ],
   "source": [
    "from ast import Pass\n",
    "import platform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "number_of_images = 250\n",
    "\n",
    "root = os.getcwd() # Don't change this\n",
    "data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "p = Path(root + data_dirname)\n",
    "p.mkdir(exist_ok=True) \n",
    "if platform.system()=='Darwin':\n",
    "  root = os.getcwd() # Don't change this\n",
    "  data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "  p = Path(root + data_dirname)\n",
    "  p.mkdir(exist_ok=True) \n",
    "else:\n",
    "  #p = Path(\"C:/Users/mwels/Documents/Uni/11. Semester/Deep learning in visual recognition/Plant_leave_diseases_dataset_without_augmentation\")\n",
    "  #p.mkdir(exist_ok=True)\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "classes = [\n",
    "  'Apple___Apple_scab',\n",
    "  'Apple___healthy',\n",
    "  'Apple___Black_rot',\n",
    "  'Apple___Cedar_apple_rust',\n",
    "  \"all\"\n",
    "  ]\n",
    "\n",
    "if \"all\" in classes:\n",
    "  classes = os.listdir(p)\n",
    "\n",
    "for c in classes:\n",
    "  print(c,end=\" \")\n",
    "  filelist = [x for x in (p/c).iterdir() if x.is_file()]\n",
    "  for f in filelist:\n",
    "    img = cv2.imread(str(f))\n",
    "    if img is None:\n",
    "      print(f'Failed to open {f}. Deleting file')\n",
    "      os.remove(str(f))\n",
    "\n",
    "\n",
    "filelist = filelist[:number_of_images]\n",
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "tilex = 3\n",
    "number_of_tiles = tilex\n",
    "tile_size = 255//tilex\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "conv_base = MobileNet(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=(tile_size, tile_size, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Flatten, Lambda, BatchNormalization\n",
    "from keras.models import Model\n",
    "from model_tools import Ranking\n",
    "import perturbations\n",
    "import os\n",
    "import keras.backend as K\n",
    "\n",
    "tiles = Input((number_of_tiles,tile_size,tile_size,3))\n",
    "layers = {}\n",
    "embedds = {}\n",
    "\n",
    "shared_conv = conv_base \n",
    "\n",
    "for i in range(number_of_tiles):\n",
    "    layers[f'tile{i}'] = Lambda(lambda x: x[:,i,:,:,:])(tiles)\n",
    "\n",
    "    layers[f'deep_layers{i}'] = shared_conv(layers[f'tile{i}'])\n",
    "    embedds[f'embedd{i}'] = Flatten()(layers[f'deep_layers{i}'])\n",
    "\n",
    "concatonation = Concatenate(axis=1)(list(embedds.values()))\n",
    "\n",
    "out = Dense(number_of_tiles*10, activation=\"relu\", kernel_initializer='he_normal')(concatonation)\n",
    "out = BatchNormalization()(out)\n",
    "out = Dense(number_of_tiles, kernel_initializer='he_normal')(out)\n",
    "out = Flatten()(out)\n",
    "out = Ranking()(out) \n",
    "\n",
    "model = Model(inputs=tiles, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \n",
    "    show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_10 (InputLayer)          [(None, 3, 85, 85,   0           []                               \n",
      "                                3)]                                                               \n",
      "                                                                                                  \n",
      " lambda_10 (Lambda)             (None, 85, 85, 3)    0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_11 (Lambda)             (None, 85, 85, 3)    0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " lambda_12 (Lambda)             (None, 85, 85, 3)    0           ['input_10[0][0]']               \n",
      "                                                                                                  \n",
      " mobilenet_1.00_224 (Functional  (None, 2, 2, 1024)  3228864     ['lambda_10[0][0]',              \n",
      " )                                                                'lambda_11[0][0]',              \n",
      "                                                                  'lambda_12[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_14 (Flatten)           (None, 4096)         0           ['mobilenet_1.00_224[0][0]']     \n",
      "                                                                                                  \n",
      " flatten_15 (Flatten)           (None, 4096)         0           ['mobilenet_1.00_224[1][0]']     \n",
      "                                                                                                  \n",
      " flatten_16 (Flatten)           (None, 4096)         0           ['mobilenet_1.00_224[2][0]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 12288)        0           ['flatten_14[0][0]',             \n",
      "                                                                  'flatten_15[0][0]',             \n",
      "                                                                  'flatten_16[0][0]']             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 30)           368670      ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 30)          120         ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 3)            93          ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_17 (Flatten)           (None, 3)            0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " ranking_3 (Ranking)            (None, 3)            0           ['flatten_17[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,597,747\n",
      "Trainable params: 3,575,799\n",
      "Non-trainable params: 21,948\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers is 14\n",
      "Number of pretrained base layers is 86\n"
     ]
    }
   ],
   "source": [
    "total_num_layers = len(model.layers)\n",
    "num_base_layers = len(conv_base.layers)\n",
    "print(f\"Total number of layers is {total_num_layers}\")\n",
    "print(f\"Number of pretrained base layers is {num_base_layers}\")\n",
    "\n",
    "for layer in model.layers[:num_base_layers]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[num_base_layers:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.PermSubsetDataGen import *\n",
    "from src.model_tools import *\n",
    "from src.permutation_tools import *\n",
    "\n",
    "x_train, x_test = train_test_split(filelist)\n",
    "\n",
    "train_generator_s = PermSubsetDataGen(x_train,\n",
    "                                    batch_size=8,\n",
    "                                    tilenumberx=tilex, vert=True)\n",
    "\n",
    "validation_generator_s = PermSubsetDataGen(x_test,\n",
    "                                        batch_size=8,\n",
    "                                        tilenumberx=tilex, vert=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "#    loss=RankingLoss(),\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[ProjectedRanksAccuracy(), PartialRanksAccuracy(), 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_generator_s.next()[1].shape)\n",
    "print(validation_generator_s.next()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "24/24 [==============================] - 12s 366ms/step - loss: 1.3918 - projection_ranks_acc: 0.5760 - partial_ranks_acc: 0.3177 - accuracy: 0.2674 - val_loss: 1.0956 - val_projection_ranks_acc: 0.6638 - val_partial_ranks_acc: 0.4107 - val_accuracy: 0.4127\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 8s 322ms/step - loss: 1.3648 - projection_ranks_acc: 0.5788 - partial_ranks_acc: 0.2992 - accuracy: 0.3155 - val_loss: 1.0874 - val_projection_ranks_acc: 0.6670 - val_partial_ranks_acc: 0.4301 - val_accuracy: 0.4286\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 8s 322ms/step - loss: 1.3024 - projection_ranks_acc: 0.5913 - partial_ranks_acc: 0.3200 - accuracy: 0.3209 - val_loss: 1.2858 - val_projection_ranks_acc: 0.6080 - val_partial_ranks_acc: 0.3162 - val_accuracy: 0.3651\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 8s 323ms/step - loss: 1.2967 - projection_ranks_acc: 0.5983 - partial_ranks_acc: 0.3553 - accuracy: 0.3369 - val_loss: 1.3879 - val_projection_ranks_acc: 0.5737 - val_partial_ranks_acc: 0.3356 - val_accuracy: 0.3175\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 8s 322ms/step - loss: 1.3564 - projection_ranks_acc: 0.5851 - partial_ranks_acc: 0.3322 - accuracy: 0.3102 - val_loss: 1.1609 - val_projection_ranks_acc: 0.6455 - val_partial_ranks_acc: 0.4412 - val_accuracy: 0.4127\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 8s 325ms/step - loss: 1.2748 - projection_ranks_acc: 0.6135 - partial_ranks_acc: 0.3681 - accuracy: 0.3476 - val_loss: 1.2739 - val_projection_ranks_acc: 0.5933 - val_partial_ranks_acc: 0.3118 - val_accuracy: 0.2857\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 8s 323ms/step - loss: 1.2728 - projection_ranks_acc: 0.6056 - partial_ranks_acc: 0.3380 - accuracy: 0.3316 - val_loss: 1.3079 - val_projection_ranks_acc: 0.6022 - val_partial_ranks_acc: 0.3996 - val_accuracy: 0.4286\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 8s 323ms/step - loss: 1.1721 - projection_ranks_acc: 0.6417 - partial_ranks_acc: 0.3733 - accuracy: 0.4011 - val_loss: 1.2182 - val_projection_ranks_acc: 0.6317 - val_partial_ranks_acc: 0.3906 - val_accuracy: 0.4127\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 8s 324ms/step - loss: 1.2903 - projection_ranks_acc: 0.5993 - partial_ranks_acc: 0.3067 - accuracy: 0.2513 - val_loss: 1.2628 - val_projection_ranks_acc: 0.6129 - val_partial_ranks_acc: 0.3304 - val_accuracy: 0.3333\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 8s 322ms/step - loss: 1.1923 - projection_ranks_acc: 0.6288 - partial_ranks_acc: 0.3409 - accuracy: 0.3476 - val_loss: 1.2365 - val_projection_ranks_acc: 0.6192 - val_partial_ranks_acc: 0.3646 - val_accuracy: 0.3492\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 8s 327ms/step - loss: 1.2526 - projection_ranks_acc: 0.6139 - partial_ranks_acc: 0.3258 - accuracy: 0.3476 - val_loss: 1.3723 - val_projection_ranks_acc: 0.5795 - val_partial_ranks_acc: 0.3326 - val_accuracy: 0.3016\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 8s 332ms/step - loss: 1.1661 - projection_ranks_acc: 0.6455 - partial_ranks_acc: 0.3738 - accuracy: 0.3850 - val_loss: 1.5379 - val_projection_ranks_acc: 0.5312 - val_partial_ranks_acc: 0.2433 - val_accuracy: 0.1905\n",
      "Epoch 13/30\n",
      "22/24 [==========================>...] - ETA: 0s - loss: 1.3144 - projection_ranks_acc: 0.5951 - partial_ranks_acc: 0.3018 - accuracy: 0.3099"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [69], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m nb_epochs \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_generator_s,\n\u001b[0;32m      4\u001b[0m           epochs \u001b[39m=\u001b[39;49m nb_epochs,\n\u001b[0;32m      5\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_generator_s,\n\u001b[0;32m      6\u001b[0m           verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\Documents\\myawesome\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs = 30\n",
    "\n",
    "model.fit(train_generator_s,\n",
    "          epochs = nb_epochs,\n",
    "          validation_data=validation_generator_s,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2022_10_27__01/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2022_10_27__01/assets\n"
     ]
    }
   ],
   "source": [
    "#model.save(\"models/2022_10_27__01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b8d5e587a4510d8571f088dd45f32758fc85cc5ecc1468b35b5979219c430b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
