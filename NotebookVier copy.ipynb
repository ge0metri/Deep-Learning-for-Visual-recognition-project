{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model that uses the fenchel-young loss and trains on 200 images \n",
    "# the images are permuted in 9 tiles and in every iteration a new permutation is generated.\n",
    "# we use a deep encoder with fixed parameters, adam optimizer, preprocessing before tiling  \n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple___Apple_scab Apple___Black_rot Apple___Cedar_apple_rust Apple___healthy 500\n"
     ]
    }
   ],
   "source": [
    "from ast import Pass\n",
    "import platform\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "number_of_images = 500\n",
    "\n",
    "root = os.getcwd() # Don't change this\n",
    "data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "p = Path(root + data_dirname)\n",
    "p.mkdir(exist_ok=True) \n",
    "if platform.system()=='Darwin':\n",
    "  root = os.getcwd() # Don't change this\n",
    "  data_dirname = '/data_test/plantvillage/' # Change as you like \n",
    "  p = Path(root + data_dirname)\n",
    "  p.mkdir(exist_ok=True) \n",
    "else:\n",
    "  #p = Path(\"C:/Users/mwels/Documents/Uni/11. Semester/Deep learning in visual recognition/Plant_leave_diseases_dataset_without_augmentation\")\n",
    "  #p.mkdir(exist_ok=True)\n",
    "  pass\n",
    "\n",
    "\n",
    "\n",
    "classes = [\n",
    "  'Apple___Apple_scab',\n",
    "  'Apple___healthy',\n",
    "  'Apple___Black_rot',\n",
    "  'Apple___Cedar_apple_rust',\n",
    "  \"all\"\n",
    "  ]\n",
    "\n",
    "if \"all\" in classes:\n",
    "  classes = os.listdir(p)\n",
    "\n",
    "for c in classes:\n",
    "  print(c,end=\" \")\n",
    "  filelist = [x for x in (p/c).iterdir() if x.is_file()]\n",
    "  for f in filelist:\n",
    "    img = cv2.imread(str(f))\n",
    "    if img is None:\n",
    "      print(f'Failed to open {f}. Deleting file')\n",
    "      os.remove(str(f))\n",
    "\n",
    "\n",
    "filelist = filelist[:number_of_images]\n",
    "print(len(filelist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tilex = 3\n",
    "number_of_tiles = tilex**2\n",
    "number_of_permutations = 1000\n",
    "target_siz = (224,224,3)\n",
    "tile_size = target_siz[0]//tilex\n",
    "sfmax = False\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "conv_base = MobileNet(weights='imagenet',\n",
    "                      include_top=False,\n",
    "                      input_shape=target_siz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Concatenate, Input, Flatten, Lambda, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import os\n",
    "\n",
    "\n",
    "#tiles = Input((number_of_tiles,tile_size,tile_size,3))\n",
    "tiles = Input(target_siz)\n",
    "\n",
    "inputs = {}\n",
    "layers = {}\n",
    "embedds = {}\n",
    "\n",
    "shared_conv = conv_base \n",
    "\n",
    "# for i in range(number_of_tiles):\n",
    "#     #inputs[f'tiles{i}'] = Input((tile_size,tile_size,3))\n",
    "#     #layers[f'tile{i}'] = Lambda(lambda x: x[:,i,:,:,:])(tiles)\n",
    "\n",
    "#     #layers[f'deep_layers{i}'] = shared_conv(inputs[f'tiles{i}'])\n",
    "#     layers[f'deep_layers{i}'] = shared_conv(layers[f'tile{i}'])\n",
    "#     embedds[f'embedd{i}'] = Flatten()(layers[f'deep_layers{i}'])\n",
    "#concatonation = Concatenate(axis=1)(list(embedds.values()))\n",
    "\n",
    "concatonation = shared_conv(tiles)\n",
    "concatonation = GlobalAveragePooling2D()(concatonation)\n",
    "\n",
    "out = Dense(number_of_tiles*50, activation=\"relu\", kernel_initializer='he_normal')(concatonation)\n",
    "if sfmax:\n",
    "    out = Dense(number_of_permutations, activation=\"softmax\", kernel_initializer='he_normal')(out)\n",
    "else:\n",
    "    out = Dense(number_of_tiles, kernel_initializer='he_normal')(out)\n",
    "out = Flatten()(out)\n",
    "\n",
    "model = Model(inputs=tiles, outputs=out)\n",
    "#model = Model(inputs=list(inputs.values()), outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, \n",
    "    show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " mobilenet_1.00_224 (Functio  (None, 7, 7, 1024)       3228864   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_3   (None, 1024)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 450)               461250    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 9)                 4059      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 9)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,694,173\n",
      "Trainable params: 3,672,285\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers is 6\n",
      "Number of pretrained base layers is 86\n"
     ]
    }
   ],
   "source": [
    "total_num_layers = len(model.layers)\n",
    "num_base_layers = len(conv_base.layers)\n",
    "print(f\"Total number of layers is {total_num_layers}\")\n",
    "print(f\"Number of pretrained base layers is {num_base_layers}\")\n",
    "\n",
    "for layer in model.layers[:3]:\n",
    "    layer.trainable=True\n",
    "for layer in model.layers[3:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.PermOneHotDataGen import *\n",
    "from src.model_tools import *\n",
    "from src.permutation_tools import *\n",
    "\n",
    "x_train, x_test = train_test_split(filelist)\n",
    "\n",
    "train_generator = PermOneHotDataGen(x_train,\n",
    "                                    batch_size=8,\n",
    "                                    tilenumberx=tilex, \n",
    "                                    shuffle_permutations=True,\n",
    "                                    one_hot_encoding=False,\n",
    "                                    stitched=True)\n",
    "\n",
    "validation_generator = PermOneHotDataGen(x_test,\n",
    "                                        batch_size=8,\n",
    "                                        tilenumberx=tilex,\n",
    "                                        shuffle_permutations=True,\n",
    "                                        stitched=True)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    name='Adam',\n",
    ")\n",
    "\n",
    "if sfmax:\n",
    "    model.compile(optimizer=optimizer,\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=['accuracy'])\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=RankingLoss(),\n",
    "        metrics=[ProjectedRanksAccuracy(), PartialRanksAccuracy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 9)\n",
      "(8, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.next()[1].shape)\n",
    "print(validation_generator.next()[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProjectedRanksAccuracy().update_state(validation_generator.next()[1], validation_generator.next()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tensorflow import keras\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLearning(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Callback to plot the learning curves of the model during training.\n",
    "    \"\"\"\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "            \n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "        \n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "        \n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15,5))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2), \n",
    "                        self.metrics[metric], \n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2), \n",
    "                            self.metrics['val_' + metric], \n",
    "                            label='val_' + metric)\n",
    "                \n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "47/47 [==============================] - 73s 2s/step - loss: 824.8886 - projection_ranks_acc: 0.7246 - partial_ranks_acc: 0.1181 - val_loss: 879.8484 - val_projection_ranks_acc: 0.7144 - val_partial_ranks_acc: 0.1203\n",
      "Epoch 2/10\n",
      "47/47 [==============================] - 71s 2s/step - loss: 550.4042 - projection_ranks_acc: 0.7668 - partial_ranks_acc: 0.1358 - val_loss: 781.9524 - val_projection_ranks_acc: 0.7358 - val_partial_ranks_acc: 0.1186\n",
      "Epoch 3/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 456.5608 - projection_ranks_acc: 0.7872 - partial_ranks_acc: 0.1348 - val_loss: 672.1764 - val_projection_ranks_acc: 0.7486 - val_partial_ranks_acc: 0.1500\n",
      "Epoch 4/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 434.7302 - projection_ranks_acc: 0.7877 - partial_ranks_acc: 0.1409 - val_loss: 523.7314 - val_projection_ranks_acc: 0.7709 - val_partial_ranks_acc: 0.1408\n",
      "Epoch 5/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 427.5387 - projection_ranks_acc: 0.7915 - partial_ranks_acc: 0.1329 - val_loss: 473.5342 - val_projection_ranks_acc: 0.7780 - val_partial_ranks_acc: 0.1337\n",
      "Epoch 6/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 415.7651 - projection_ranks_acc: 0.7944 - partial_ranks_acc: 0.1386 - val_loss: 412.7678 - val_projection_ranks_acc: 0.7918 - val_partial_ranks_acc: 0.1392\n",
      "Epoch 7/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 409.4612 - projection_ranks_acc: 0.8032 - partial_ranks_acc: 0.1449 - val_loss: 439.1723 - val_projection_ranks_acc: 0.7816 - val_partial_ranks_acc: 0.1149\n",
      "Epoch 8/10\n",
      "47/47 [==============================] - 70s 1s/step - loss: 400.6672 - projection_ranks_acc: 0.8062 - partial_ranks_acc: 0.1404 - val_loss: 379.5392 - val_projection_ranks_acc: 0.8159 - val_partial_ranks_acc: 0.1398\n",
      "Epoch 9/10\n",
      "47/47 [==============================] - 71s 2s/step - loss: 399.7544 - projection_ranks_acc: 0.8068 - partial_ranks_acc: 0.1369 - val_loss: 381.1665 - val_projection_ranks_acc: 0.8083 - val_partial_ranks_acc: 0.1253\n",
      "Epoch 10/10\n",
      "47/47 [==============================] - 71s 2s/step - loss: 390.9493 - projection_ranks_acc: 0.8133 - partial_ranks_acc: 0.1468 - val_loss: 379.6635 - val_projection_ranks_acc: 0.8145 - val_partial_ranks_acc: 0.1543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1caff4af220>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epochs = 10\n",
    "\n",
    "model.fit(train_generator,\n",
    "          epochs = nb_epochs,\n",
    "          validation_data=validation_generator,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 27). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2022_11_02__02tiled9\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/2022_11_02__02tiled9\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"models/2022_11_02__02tiled9\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4b8d5e587a4510d8571f088dd45f32758fc85cc5ecc1468b35b5979219c430b5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
